#!/usr/bin/env python3
"""
ğŸ¥‹ Judo Framework - Runner Personalizado para DemostraciÃ³n

Este runner estÃ¡ configurado especÃ­ficamente para demostrar todas las capacidades
de Judo Framework. Incluye configuraciÃ³n optimizada para reportes, logging y
organizaciÃ³n de resultados.

Autor: Felipe Farias A.
Fecha: 2025
"""

from judo.runner.base_runner import BaseRunner
import os
import sys
from pathlib import Path

# ============================================
# CONFIGURACIÃ“N DE DEBUG Y LOGGING
# ============================================

# Controla el nivel de debug del reporter de Judo
# 'true' = Muestra informaciÃ³n detallada de debug
# 'false' = Solo muestra informaciÃ³n esencial
os.environ['JUDO_DEBUG_REPORTER'] = 'false'

# Opcional: Configurar nivel de logging adicional
# os.environ['JUDO_LOG_LEVEL'] = 'INFO'


class MyRunner(BaseRunner):
    """
    Runner personalizado que extiende BaseRunner de Judo Framework.
    
    Esta clase configura todos los aspectos necesarios para ejecutar
    los tests de demostraciÃ³n con la configuraciÃ³n Ã³ptima.
    """

    basedir = "./judo_reports"

    def __init__(self):
        """
        Inicializa el runner con configuraciÃ³n personalizada.
        
        Configuraciones principales:
        - Rutas de archivos y directorios
        - GeneraciÃ³n de reportes
        - Logging de peticiones/respuestas
        - ConfiguraciÃ³n de paralelizaciÃ³n
        """
        super().__init__(
            # ============================================
            # CONFIGURACIÃ“N DE DIRECTORIOS
            # ============================================
            
            # Directorio donde estÃ¡n los archivos .feature
            # "../features" = subir un nivel desde Runner/ y entrar a features/
            features_dir="../features",
            
            # Directorio donde se guardarÃ¡n todos los reportes
            # "./judo_reports" = crear carpeta judo_reports dentro de Runner/
            output_dir=self.basedir,

            # ============================================
            # CONFIGURACIÃ“N DE REPORTES
            # ============================================
            
            # Generar reportes en formato JSON cucumber (compatible con CI/CD)
            # Ãštil para integraciÃ³n con XRAY, Jenkins, GitHub Actions, etc.
            generate_cucumber_json=True,
            
            # Directorio especÃ­fico para reportes JSON
            cucumber_json_dir=f"{self.basedir}/cucumber-json",

            # ============================================
            # CONFIGURACIÃ“N DE EJECUCIÃ“N
            # ============================================
            
            # EjecuciÃ³n en paralelo
            # False = Ejecutar tests secuencialmente (mÃ¡s estable para demo)
            # True = Ejecutar tests en paralelo (mÃ¡s rÃ¡pido)
            parallel=False,
            
            # NÃºmero mÃ¡ximo de workers para ejecuciÃ³n paralela
            # Solo se usa si parallel=True
            max_workers=2,

            # ============================================
            # CONFIGURACIÃ“N DE LOGGING DE API
            # ============================================
            
            # Guardar todas las peticiones y respuestas HTTP
            # Extremadamente Ãºtil para debugging y auditorÃ­a
            save_requests_responses=True,
            
            # Directorio donde se guardan los logs de API
            # Cada escenario tendrÃ¡ su propia carpeta con:
            # - Request completo (headers, body, URL)
            # - Response completo (status, headers, body)
            requests_responses_dir=f"{self.basedir}/api_logs"
        )

    def run_smoke_tests(self):
        """
        Ejecuta todos los tests de demostraciÃ³n en inglÃ©s.
        Utiliza el tag @eng_examples_all que incluye todos los ejemplos
        en inglÃ©s del archivo all_examples.feature.
        """
        return self.run(tags=["@eng_examples_all"])
    


def print_banner():
    """Imprime un banner informativo al inicio."""
    print("=" * 60)
    print("ğŸ¥‹ JUDO FRAMEWORK - PROYECTO DE DEMOSTRACIÃ“N")
    print("=" * 60)
    print("ğŸ“‹ Este runner ejecuta tests que demuestran:")
    print("   â€¢ MÃ©todos HTTP (GET, POST, PUT, PATCH, DELETE)")
    print("   â€¢ Validaciones avanzadas (JSONPath, esquemas)")
    print("   â€¢ Manejo de variables y archivos")
    print("   â€¢ Flujos de trabajo complejos")
    print("   â€¢ Reportes detallados y logging")
    print("=" * 60)


def print_results_summary(results):
    """
    Imprime un resumen detallado de los resultados.
    
    Args:
        results (dict): Resultados de la ejecuciÃ³n
    """
    print("\n" + "=" * 60)
    print("ğŸ“Š RESUMEN DE RESULTADOS")
    print("=" * 60)
    
    total = results.get('total', 0)
    passed = results.get('passed', 0)
    failed = results.get('failed', 0)
    
    if total > 0:
        success_rate = (passed / total) * 100
        print(f"âœ… Tests exitosos: {passed}")
        print(f"âŒ Tests fallidos: {failed}")
        print(f"ğŸ“ˆ Total ejecutados: {total}")
        print(f"ğŸ¯ Tasa de Ã©xito: {success_rate:.1f}%")
        
        if success_rate == 100:
            print("ğŸ‰ Â¡Todos los tests pasaron exitosamente!")
        elif success_rate >= 80:
            print("ğŸ‘ La mayorÃ­a de tests pasaron correctamente")
        else:
            print("âš ï¸  Varios tests fallaron, revisa los reportes")
    else:
        print("âš ï¸  No se ejecutaron tests")
    
    print("=" * 60)


def print_report_locations():
    """Imprime las ubicaciones de los reportes generados."""
    print("\nğŸ“„ REPORTES GENERADOS:")
    print("-" * 30)
    
    # Verificar si existen los directorios de reportes
    reports_dir = Path("./judo_reports")
    
    if reports_dir.exists():
        html_report = reports_dir / "test_execution_report.html"
        if html_report.exists():
            print(f"ğŸŒ Reporte HTML: {html_report.absolute()}")
        
        json_dir = reports_dir / "cucumber-json"
        if json_dir.exists():
            print(f"ğŸ“‹ Reportes JSON: {json_dir.absolute()}")
        
        api_logs_dir = reports_dir / "api_logs"
        if api_logs_dir.exists():
            print(f"ğŸ” Logs de API: {api_logs_dir.absolute()}")
    
    print("-" * 30)


# ============================================
# EJECUCIÃ“N PRINCIPAL
# ============================================

if __name__ == "__main__":
    """
    Punto de entrada principal del runner.
    
    Este bloque se ejecuta cuando se llama directamente al script:
    python runner.py
    """
    
    # Cambiar al directorio correcto para ejecuciÃ³n
    # Esto asegura que las rutas relativas funcionen correctamente
    script_dir = os.path.dirname(os.path.abspath(__file__))
    os.chdir(script_dir)
    
    # Mostrar banner informativo
    print_banner()
    
    # Mostrar informaciÃ³n de configuraciÃ³n
    print(f"ğŸ“ Directorio de features: {os.path.abspath('../features')}")
    print(f"ğŸ“Š Directorio de reportes: {os.path.abspath('./judo_reports')}")
    print(f"ğŸ Python version: {sys.version.split()[0]}")
    
    try:
        # Crear instancia del runner
        runner = MyRunner()
        
        print("\nğŸš€ Iniciando ejecuciÃ³n de tests...")
        
        # Ejecutar tests principales (inglÃ©s)
        results = runner.run_smoke_tests()
        
        # Mostrar resumen de resultados
        print_results_summary(results)
        
        # Mostrar ubicaciones de reportes
        print_report_locations()
        
        # Mensaje final basado en resultados
        if results.get('total', 0) > 0:
            if results.get('failed', 0) == 0:
                print("\nğŸ‰ Â¡EjecuciÃ³n completada exitosamente!")
                print("ğŸ’¡ Abre el reporte HTML para ver detalles completos")
            else:
                print("\nâš ï¸  EjecuciÃ³n completada con algunos fallos")
                print("ğŸ’¡ Revisa los logs de API para debugging")
        else:
            print("\nâŒ No se ejecutaron tests")
            print("ğŸ’¡ Verifica que los archivos .feature tengan los tags correctos")
    
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  EjecuciÃ³n interrumpida por el usuario")
        sys.exit(1)
    
    except Exception as e:
        print(f"\nâŒ Error durante la ejecuciÃ³n: {e}")
        print("\nğŸ”§ POSIBLES SOLUCIONES:")
        print("   1. Ejecuta 'python ../debug_judo.py' para diagnÃ³stico")
        print("   2. Verifica que Judo Framework estÃ© instalado: 'pip install judo-framework'")
        print("   3. Verifica la estructura de archivos .feature")
        print("   4. Revisa la conectividad de red")
        sys.exit(1)
